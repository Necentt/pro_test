{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=openai_api_key,\n",
    "    model='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Борис\\PycharmProjects\\pro_test\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Привет! LLM расшифровывается как Long Short-Term Memory, что является типом рекуррентной нейронной сети. Она используется для обработки последовательных данных, сохранения долгосрочных зависимостей и предотвращения проблемы затухающих градиентов. LLM имеет способность запоминать информацию на протяжении длительного временного интервала, что делает ее эффективной для работы с различными задачами, такими как анализ текста, машинный перевод, распознавание речи и другие.'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage\n",
    ")\n",
    "\n",
    "def get_user_msg(user_msg: str):\n",
    "    messages = [\n",
    "        SystemMessage(content='Ты умный ассистент, отвечающий на вопросы пользователя о файлах, содержащихся в базе данных. Полезные для ответа части текста из файлов будут поданы в контексте. Используй их, чтобы дать точный и полный ответ на вопрос пользователя. Не матерись. Все матерные слова заменяй на звездочки.'),\n",
    "        HumanMessage(content=user_msg)\n",
    "    ]\n",
    "    return chat(messages).content\n",
    "\n",
    "get_user_msg(\"Привет, расскажи про LLM\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "DATA_PATH = 'data'\n",
    "def load_documents():\n",
    "    loader = DirectoryLoader(DATA_PATH, glob='*.md')\n",
    "    documents = loader.load()\n",
    "    return documents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "def split_text(documents: list):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=500,\n",
    "        length_function=len,\n",
    "        add_start_index=True\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "    document = chunks[10]\n",
    "    print(document.page_content)\n",
    "    print(document.metadata)\n",
    "    return chunks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import shutil\n",
    "\n",
    "\n",
    "CHROMA_PATH = \"chroma\"\n",
    "\n",
    "\n",
    "def save_to_chroma(chunks: list):\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)\n",
    "    db = Chroma.from_documents(\n",
    "        chunks, OpenAIEmbeddings(), persist_directory=CHROMA_PATH\n",
    "    )\n",
    "    db.persist()\n",
    "    print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 documents into 102 chunks.\n",
      "Формат: видео\n",
      "\n",
      "Пик популярности: январь\n",
      "\n",
      "Где расходился: «Тикток», «Инстаграм»*\n",
      "\n",
      "С премьеры «Образцового самца» прошло более 20 лет, а мемный потенциал картины в полном объеме раскрыли только в 2023 году, когда дуэль взглядов актеров Бена Стиллера и Оуэна Уилсона сделали мемным шаблоном. В мемах Стиллер олицетворяет ничего не подозревающего человека, который был счастлив, пока не столкнулся с Уилсоном — неким препятствием или разочаровывающим обстоятельством.\n",
      "{'source': 'data\\\\memes.md', 'start_index': 2145}\n",
      "Saved 102 chunks to chroma.\n"
     ]
    }
   ],
   "source": [
    "def generate_data_store():\n",
    "    documents = load_documents()\n",
    "    chunks = split_text(documents)\n",
    "    save_to_chroma(chunks)\n",
    "generate_data_store()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import argparse\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\"\n",
    "def main(query_text):\n",
    "\n",
    "    # Prepare the DB.\n",
    "    embedding_function = OpenAIEmbeddings()\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "\n",
    "    # Search the DB.\n",
    "    results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "    if len(results) == 0 or results[0][1] < 0.7:\n",
    "        print(f\"Unable to find matching results.\")\n",
    "        return\n",
    "\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "    print(prompt)\n",
    "\n",
    "    model = ChatOpenAI()\n",
    "    response_text = model.predict(prompt)\n",
    "\n",
    "    sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    "    formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "    print(formatted_response)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "Формат: мультиформатный\n",
      "\n",
      "Пик популярности: зима, но вообще — весь год\n",
      "\n",
      "Где расходился: «Тикток», «Инстаграм»*, «Ютуб»\n",
      "\n",
      "Сигмами называют крутых парней — главных героев «Бойцовского клуба», «Острых козырьков» или «Джона Уика». И тех, кто очень хочет быть на них похожим и видит в персонажах буквально себя. Смысл термина постоянно трансформируется. Сигмы и одинокие волки, и сверхуспешные трудоголики, и образцы маскулинности, которые с уважением относятся к окружающим.\n",
      "\n",
      "---\n",
      "\n",
      "Хотя сигмы обсуждались и до 2023, в этом году мы как-то особенно часто видели людей, которые особым образом хмурили брови и надували губы, выражая одобрение происходящему. А списана гримаса как раз с одного из главных сигм поп-культуры — Патрика Бейтмана из «Американского психопата».\n",
      "\n",
      "«Образовый самец» оборачивается\n",
      "\n",
      "За что мы любим мем: безумные взгляды легендарных персонажей\n",
      "\n",
      "Формат: видео\n",
      "\n",
      "Пик популярности: январь\n",
      "\n",
      "Где расходился: «Тикток», «Инстаграм»*\n",
      "\n",
      "---\n",
      "\n",
      "Девушки, в свою очередь, обсуждали то, о чем они часто думают. Так появились мемы формата «А это моя Римская империя». Например, для многих это сериал «Сплетница» или выступления любимого музыканта.\n",
      "\n",
      "Самоуверенный Шариков\n",
      "\n",
      "За что мы любим мем: верим в планы Шарикова\n",
      "\n",
      "Формат: картинки\n",
      "\n",
      "Пик популярности: конец сентября — начало октября\n",
      "\n",
      "Где расходился: «Вконтакте», «Телеграм»\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: Кто такие Сигмы?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Борис\\PycharmProjects\\pro_test\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Сигмы - это крутые парни, главные герои из различных фильмов и сериалов, которых люди хотят быть похожими и видят себя в них. Сигмы также представляют собой образцы маскулинности, которые уважительно относятся к окружающим.\n",
      "Sources: ['data\\\\memes.md', 'data\\\\memes.md', 'data\\\\memes.md']\n"
     ]
    }
   ],
   "source": [
    "main('Кто такие Сигмы?')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}