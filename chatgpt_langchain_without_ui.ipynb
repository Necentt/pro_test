{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=openai_api_key,\n",
    "    model='gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'Привет! LLM - это сокращение от \"Master of Laws\", что в переводе с английского означает \"Магистр права\". LLM - это академическая степень, которую можно получить после окончания юридического образования. Программы LLM предоставляют студентам возможность углубить свои знания в определенной области права или получить более широкий обзор различных правовых дисциплин.\\n\\nПрограммы LLM предлагаются во многих университетах по всему миру. Они могут быть ориентированы на различные специализации, такие как корпоративное право, международное право, право интеллектуальной собственности и др. Продолжительность программы обычно составляет один год, но в некоторых случаях может быть и двухлетней.\\n\\nLLM-программы предлагают студентам возможность изучать различные аспекты права, а также развивать навыки анализа, исследования и письма. Эта степень может быть полезной для тех, кто хочет продолжить карьеру в юридической области, работать в правительственных организациях, юридических фирмах или международных организациях.\\n\\nНадеюсь, это информация о LLM была полезной для тебя! Если у тебя есть еще вопросы, не стесняйся задавать.'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage\n",
    ")\n",
    "\n",
    "def get_user_msg(user_msg: str):\n",
    "    messages = [\n",
    "        SystemMessage(content='Ты умный ассистент, отвечающий на вопросы пользователя о файлах, содержащихся в базе данных. Полезные для ответа части текста из файлов будут поданы в контексте. Используй их, чтобы дать точный и полный ответ на вопрос пользователя. Не матерись. Все матерные слова заменяй на звездочки.'),\n",
    "        HumanMessage(content=user_msg)\n",
    "    ]\n",
    "    return chat(messages).content\n",
    "\n",
    "get_user_msg(\"Привет, расскажи про LLM\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "DATA_PATH = 'data'\n",
    "def load_documents():\n",
    "    loader = DirectoryLoader(DATA_PATH, glob='*.md')\n",
    "    documents = loader.load()\n",
    "    return documents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "def split_text(documents: list):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=500,\n",
    "        length_function=len,\n",
    "        add_start_index=True\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "    document = chunks[10]\n",
    "    print(document.page_content)\n",
    "    print(document.metadata)\n",
    "    return chunks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import shutil\n",
    "\n",
    "\n",
    "CHROMA_PATH = \"chroma\"\n",
    "\n",
    "\n",
    "def save_to_chroma(chunks: list):\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)\n",
    "    db = Chroma.from_documents(\n",
    "        chunks, OpenAIEmbeddings(), persist_directory=CHROMA_PATH\n",
    "    )\n",
    "    db.persist()\n",
    "    print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 documents into 39 chunks.\n",
      "Подкрадулями и бархатными тягами называли любую странную обувь. Если первое произошло от дословного перевода слова sneakers, то второе — от голосового сообщения из «Вотсапа», в котором неизвестный мужчина воодушевленно о чем-то говорит: «Что за тяги такие, бархатные тяги, ребята? Уф-ф-ф. Кефтеме».\n",
      "\n",
      "В итоге с помощью этих слов не только иронизировали над кроссовками с острыми носами, но и хвастались собственной обувью.\n",
      "\n",
      "Я в шоке Давай\n",
      "\n",
      "За что мы любим мем: он поддержит нас в любых начинаниях\n",
      "\n",
      "Формат: видео, крылатая фраза\n",
      "\n",
      "Пик популярности: конец марта\n",
      "\n",
      "Где расходился: «Тикток», «Инстаграм»*\n",
      "\n",
      "Кто мог подумать, что короткий отрывок из обзора на мороженое «Баунти» так разойдется. Но тут сошлось все: и эмоциональная яркая фраза, и ее универсальность, и атмосфера одобрения. Все бы хотели такого друга, который даже в состоянии шока от идеи все равно тебя поддержит.\n",
      "\n",
      "Папа римский в Balenciaga\n",
      "\n",
      "За что мы любим мем: нейросети раскрыли свой мемный потенциал\n",
      "\n",
      "Формат: картинки\n",
      "{'source': 'data\\\\memes.md', 'start_index': 4729}\n",
      "Saved 39 chunks to chroma.\n"
     ]
    }
   ],
   "source": [
    "def generate_data_store():\n",
    "    documents = load_documents()\n",
    "    chunks = split_text(documents)\n",
    "    save_to_chroma(chunks)\n",
    "generate_data_store()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import argparse\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\"\n",
    "def main(query_text):\n",
    "\n",
    "    # Prepare the DB.\n",
    "    embedding_function = OpenAIEmbeddings()\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "\n",
    "    # Search the DB.\n",
    "    results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "    if len(results) == 0 or results[0][1] < 0.7:\n",
    "        print(f\"Unable to find matching results.\")\n",
    "        return\n",
    "\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "    print(prompt)\n",
    "\n",
    "    model = ChatOpenAI()\n",
    "    response_text = model.predict(prompt)\n",
    "\n",
    "    sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    "    formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "    print(formatted_response)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Answer the question based only on the following context:\n",
      "\n",
      "Возглас одобрения с ненормативной лексикой, который рифмуется с «могучий», прицепился к псу в рунете. Так Чиро получил популярность в России, а заодно стал продолжателем мемных традиций котенка Чмони.\n",
      "\n",
      "Сигмы\n",
      "\n",
      "За что мы любим мем: попытка переосмыслить маскулинность — то ли в шутку, то ли всерьез\n",
      "\n",
      "Формат: мультиформатный\n",
      "\n",
      "Пик популярности: зима, но вообще — весь год\n",
      "\n",
      "Где расходился: «Тикток», «Инстаграм»*, «Ютуб»\n",
      "\n",
      "Сигмами называют крутых парней — главных героев «Бойцовского клуба», «Острых козырьков» или «Джона Уика». И тех, кто очень хочет быть на них похожим и видит в персонажах буквально себя. Смысл термина постоянно трансформируется. Сигмы и одинокие волки, и сверхуспешные трудоголики, и образцы маскулинности, которые с уважением относятся к окружающим.\n",
      "\n",
      "---\n",
      "\n",
      "Формат: мультиформатный\n",
      "\n",
      "Пик популярности: зима, но вообще — весь год\n",
      "\n",
      "Где расходился: «Тикток», «Инстаграм»*, «Ютуб»\n",
      "\n",
      "Сигмами называют крутых парней — главных героев «Бойцовского клуба», «Острых козырьков» или «Джона Уика». И тех, кто очень хочет быть на них похожим и видит в персонажах буквально себя. Смысл термина постоянно трансформируется. Сигмы и одинокие волки, и сверхуспешные трудоголики, и образцы маскулинности, которые с уважением относятся к окружающим.\n",
      "\n",
      "Хотя сигмы обсуждались и до 2023, в этом году мы как-то особенно часто видели людей, которые особым образом хмурили брови и надували губы, выражая одобрение происходящему. А списана гримаса как раз с одного из главных сигм поп-культуры — Патрика Бейтмана из «Американского психопата».\n",
      "\n",
      "«Образовый самец» оборачивается\n",
      "\n",
      "За что мы любим мем: безумные взгляды легендарных персонажей\n",
      "\n",
      "Формат: видео\n",
      "\n",
      "Пик популярности: январь\n",
      "\n",
      "Где расходился: «Тикток», «Инстаграм»*\n",
      "\n",
      "---\n",
      "\n",
      "Хотя сигмы обсуждались и до 2023, в этом году мы как-то особенно часто видели людей, которые особым образом хмурили брови и надували губы, выражая одобрение происходящему. А списана гримаса как раз с одного из главных сигм поп-культуры — Патрика Бейтмана из «Американского психопата».\n",
      "\n",
      "«Образовый самец» оборачивается\n",
      "\n",
      "За что мы любим мем: безумные взгляды легендарных персонажей\n",
      "\n",
      "Формат: видео\n",
      "\n",
      "Пик популярности: январь\n",
      "\n",
      "Где расходился: «Тикток», «Инстаграм»*\n",
      "\n",
      "С премьеры «Образцового самца» прошло более 20 лет, а мемный потенциал картины в полном объеме раскрыли только в 2023 году, когда дуэль взглядов актеров Бена Стиллера и Оуэна Уилсона сделали мемным шаблоном. В мемах Стиллер олицетворяет ничего не подозревающего человека, который был счастлив, пока не столкнулся с Уилсоном — неким препятствием или разочаровывающим обстоятельством.\n",
      "\n",
      "---\n",
      "\n",
      "Answer the question based on the above context: Кто такие Сигмы?\n",
      "\n",
      "Response: Сигмы - это термин, который используется для описания крутых парней или главных героев фильмов, таких как \"Бойцовский клуб\", \"Острые козырьки\" или \"Джон Уик\". Также этот термин может относиться к тем, кто хочет быть похожим на таких персонажей и видит себя в них. Сигмы могут быть как одинокими волками, так и успешными трудоголиками, которые уважают окружающих.\n",
      "Sources: ['data\\\\memes.md', 'data\\\\memes.md', 'data\\\\memes.md']\n"
     ]
    }
   ],
   "source": [
    "main('Кто такие Сигмы?')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}